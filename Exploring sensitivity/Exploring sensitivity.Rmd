---
title: "Exploring sensitivity of Time-varing model"
output: html_notebook
---
testing RLS algorithm 

Packages and such
```{r}
library(ggplot2)
library(devtools)
library(tibble)
set.seed(100) #for consistency in noise function
load_all()
```

Create two different sets of parameters and training loads, and a tibble that
will be used later. 
```{r}
params_list_1 = list(c(250,.1,.1,25,15), c(250,.5,.5,25,1))
training_load_1 <- c(rep(100,100))
#shortened_training_load <- training_load[1:50]
# first_length <- length(shortened_training_load)
# second_legth <- length(training_load)-length(shortened_training_load)

#to graph actual parameter values against the predicted ones


```


Creating a model (with the time invariant model) where the first 50 days use the 
first set of paramters and the last 50 days use the second set. 


```{r}

varying_performance <- function(params_list,
                                training_load,
                                change_date){
  c(
    predictedPerformance(params_list[[1]], training_load[1:change_date]),
    na.omit(predictedPerformance(params_list[[2]], training_load)[change_date+1:length(training_load)])
  )
}
non_noisy_perf_1 <- varying_performance(params_list_1, training_load_1, 50)
non_noisy_perf_1

# 
# non_noisy_performance_1 <- predictedPerformance(params_1, shortened_training_load)
# non_noisy_performance_2 <- predictedPerformance(params_2, training_load)[51:100]
# non_noisy_performance_2 
# non_noisy_perf = c(non_noisy_performance_1, non_noisy_performance_2[51:100])
# non_noisy_perf


```


Trying to recover the parameters with the time-varying model. Thought it was easier to make a function 
`prediction_with_alpha(performance, alpha, ...)` that plots the RLS algorithm --  with `alpha=alpha` and `predicted_performance = predicted parameter` -- given in `...`against that acutal paramters. 
```{r, eval = FALSE}
#transforming the parameter output of RLS function
lists_to_tibble <- function(list_of_lists){
  len=length(list_of_lists)
  list_0 <- c(rep(0,len))
  out=tibble(
    "day" = 1:len,
    "p_0" = list_0,
    "k_1" = list_0,
    "k_2" = list_0,
    "tau_1" = list_0,
    "tau_2" = list_0
  )
  for(i in 1:len){
    for(j in 2:6){
     out[i,j] = list_of_lists[[i]][[j-1]] 
    }
  }
  out
}


#to be able to plot the actual paramters agains the predicted parameters
actual_params_to_tib <- function(params_list, 
                                 training_load, 
                                 length_first_params, 
                                 length_second_params = length(training_load)
){
  params_1 = params_list[[1]]
  params_2 = params_list[[2]]
  first_length = length_first_params 
  second_length = length_second_params - length_first_params 
  tibble(
    "day" = 1:length(training_load),
    "p_0" = c(rep(params_1[[1]], first_length),
              rep(params_2[[1]], second_length)
    ),
    "k_1" = c(rep(params_1[[2]], first_length),
              rep(params_2[[2]], second_length)
    ),
    
    "k_2" = c(rep(params_1[[3]], first_length),
              rep(params_2[[3]], second_length)
    ),
    "tau_1" = c(rep(params_1[[4]], first_length),
                rep(params_2[[4]], second_length)
    ),
    "tau_2" = c(rep(params_1[[5]], first_length),
                rep(params_2[[5]], second_length)
    )
  )
}

#The actually cool function
prediction_with_alpha <- function(performance, alpha, ...){
  prediction_non_noisy <- RLS_predicted_performance(
    training_load_1,
    performance,
    250,
    alpha = alpha,
    delta = 1000,
    c(1,50),
    1,
    c(1,50),
    1
  )
  
  actual_param_tib_flat <- actual_params_to_tib(params_list_1, 
                                                training_load_1, 
                                                length(shortened_training_load), 
                                                length(training_load)
  )
                                                
  parameter_tibble_pred <- lists_to_tibble(prediction_non_noisy[[2]])
  
  
  plot <- ggplot(parameter_tibble_pred, aes(x = day, y = ...))+
    geom_line()+
    geom_line(data = actual_param_tib_flat, color= "red")
  plot
}

prediction_with_alpha(non_noisy_perf, .0001, tau_1)
prediction_with_alpha(non_noisy_perf, .0001, tau_2)

# prediction_non_noisy <- RLS_predicted_performance(
#       training_load,
#       non_noisy_perf,
#       250,
#       alpha = .0001,
#       delta =1000,
#       c(1,50),
#       1,
#       c(1,50),
#       1
#     )
# prediction_non_noisy[[2]]
```
After some time, `tau_1` and `tau_2` flip between the acutal values. They also
take a unique value, so they are "trading" in some sense. 


Sometimes, both `k_1` and `k_2` are negative while `tau_1` and `tau_2` seem to filp
Prehaps the matrix of SSE is symmetric. Can then reduce the computational load. This is true:

```{r, eval = FALSE}
prediction_non_noisy <- RLS_predicted_performance(
      training_load_1,
      non_noisy_perf,
      250,
      alpha = .0001,
      delta = 1000,
      c(1,50),
      1,
      c(1,50),
      1
)    
#This is the matrix for the RLS model SSE on day 5
(symm_matrix <- as.data.frame(prediction_non_noisy[[4]][5,,]))
```



Changing values of alpha effects how the algorithm recovers the parameter.
In the given value, .00000000000000001, the algorithm can recover the first
set of parameters in 3 data points, For reasonable values (like one or one or
two decimal points) the data can recover the first set in 7 data points. However,
for incredibly small values, the model converges on the wrong values, but more
values can still recover the origional parameters, just at the slow 7 data point rate

prehaps to predict paramters, we should throw out old data (which does have a recursive algorithm in the
same book that I have).



Applying noise to this model (with helper function that makes noise)
```{r}
noise <- function(x,  sd){
  x+rnorm(1, mean = 0, sd = sd)
}

noisy_perf1_1 = purrr::map_dbl(non_noisy_perf_1, noise, sd = 1)
```


The noise function and a check that it works:
```{r}
performance_tib = tibble::tibble(
  day = c(1:100),
  non_noisy = non_noisy_perf_1,
  noisy = noisy_perf_1 
)
 
# plot <- ggplot(performance_tib, aes(x = day, y = non_noisy))+
#   geom_line(color = "red")+
#   geom_line(aes(y=noisy), color = "blue")
# plot
```



Running RLS algorithm with the noisy performance
```{r, eval=FALSE}
prediction_noisy <- RLS_predicted_performance(
      training_load_1,
      noisy_perf_1,
      250,
      alpha = .55,
      delta = 1000,
      c(1,50),
      1,
      c(1,50),
      1
    )
#prediction_noisy[[2]]

data_1 <- tibble(
  "day" = c(1:100),
  "pred_perf" = as.numeric(prediction_noisy[[1]]),
  "perf" = noisy_perf_1
)

plot_1 <- ggplot(data_1, aes(day, pred_perf))+
  geom_line()+
  geom_line(aes(x = day, y=perf), color ="red")
plot_1
```
This is giving weird results; the parameters are not being recovered. 



Now lets try recovering the same paramters with a different shape of training load.

```{r}
training_triangle <- c(1:50, 50:1)

actual_param_tib_triangle <- actual_params_to_tib(params_1, 
                                                  params_2, 
                                                  training_triangle, 
                                                  50, 
                                                  length(training_load)
)



```




